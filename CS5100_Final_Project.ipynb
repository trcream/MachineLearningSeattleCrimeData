{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS5100 Final Project"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Trenton Creamer\n",
    "\n",
    "Goal: This assignment will allow you to apply your knowledge of machine learning that you have aquired in this course on a real-world dataset of your choosing per the assignment specifications.\n",
    "\n",
    "Complete the notebook and demonstrate your mastery of the topic."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "In this section describe any packages that need to be installed or any additional setup that needs to take place before trying to run code.\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from utility.util import configure_plots\n",
    "\n",
    "configure_plots()\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from utility.util import pair_plot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utility.util import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# import matplotlib.pyplot as plt\n",
    "# from utility.util import configure_plots\n",
    "\n",
    "# configure_plots()\n",
    "\n",
    "# from sklearn.preprocessing import normalize\n",
    "\n",
    "# from utility.util import pair_plot\n",
    "\n",
    "# from sklearn.model_selection import train_test_split\n",
    "\n",
    "# from utility.util import Model\n",
    "\n",
    "import datetime"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem\n",
    "\n",
    "In this section, you will explain the problem you are trying to solve, the things you are trying to learn, and how you want to visualize the results.\n",
    "\n",
    "I want to use this machine learning model to better predict patterns and trends in 911 calls. This could help the Seattle police department with staffing and resource allocation. If they know that certain 911 calls are more frequent during different seasons or during times of the day, then they can be better prepared for this. \n",
    "\n",
    "I could also use location to look for clusters or patterns in the data. This could help the police determine where to keep police members present. For example, hotspots of crime could potentially have a mobile police station parked there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "In this section you will describe the dataset (corpus) you are using. Explain who collected the data, how they did it, the manner in which it was stored, the way you accessed the data, what steps you will have to do to clean it, and so on. Provide any relavent details."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the Data\n",
    "\n",
    "Add the code to download/query you data. If your data is already downloaded, then load it into your program here. Then add the code to clean it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello World\n",
      "['Address', 'Type', 'Datetime', 'Latitude', 'Longitude', 'Report Location', 'Incident Number']\n",
      "['607 3RD AVE', 'Rescue Elevator', '4/1/22 0:02', '47.602813', '-122.331449', 'POINT (-122.331449 47.602813)', 'F220037342']\n",
      "['6TH AVE W / W MCGRAW ST', 'Triaged Incident', '4/1/22 0:03', '47.639596', '-122.36495', 'POINT (-122.36495 47.639596)', 'F220037343']\n",
      "['500 5th Ave', 'Aid Response', '4/1/22 0:07', '47.602985', '-122.328535', 'POINT (-122.328535 47.602985)', 'F220037344']\n",
      "['401 Lenora St', 'Aid Response', '4/1/22 0:09', '47.613838', '-122.341324', 'POINT (-122.341324 47.613838)', 'F220037345']\n",
      "['2900 1st Ave', 'Aid Response', '4/1/22 0:14', '47.616918', '-122.352507', 'POINT (-122.352507 47.616918)', 'F220037347']\n"
     ]
    }
   ],
   "source": [
    "def parse_csv(line):\n",
    "    return line.strip().split(',')\n",
    "\n",
    "def load_data(path, parsefn):\n",
    "    with open(path) as file:\n",
    "        return [parsefn(line) for line in file]\n",
    "\n",
    "policeCallData = load_data('Seattle_Real_Time_Fire_911_CallsCleaned.csv', parse_csv)\n",
    "print(\"Hello World\")\n",
    "# for i in range(5):\n",
    "#     print(policeCallData[i])\n",
    "\n",
    "\n",
    "\n",
    "headings, data = policeCallData[0], policeCallData[1:]\n",
    "print(headings)\n",
    "for i in range(5):\n",
    "    print(data[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More Cleaning Code\n",
    "# Convert the Datetime column to a datetime data dype\n",
    "# get the index of the Datetime columns\n",
    "\n",
    "\n",
    "# Use buckets for the different hours \n",
    "# Can use dates for seasons \n",
    "# Days of the week \n",
    "\n",
    "# Geo map the coordinates \n",
    "# Geopy geo pandas - can use lat and long \n",
    "\n",
    "# Encode days of the week\n",
    "# morning afternoon evening \n",
    "# Breakign out the datetime it different fields \n",
    "\n",
    "# Get the column index of the datetime string column\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "# Define the datetime format string\n",
    "datetime_format = '%m/%d/%y %H:%M'\n",
    "\n",
    "datetime_col_index = headings.index('Datetime')\n",
    "\n",
    "\n",
    "# Convert each datetime string to a timestamp data type\n",
    "for row in data:\n",
    "    # Getting the datetime string \n",
    "    datetime_string = row[datetime_col_index]\n",
    "    # print(datetime_string)\n",
    "    \n",
    "    # Convert the string to a datetime object \n",
    "    datetime_object = datetime.strptime(datetime_string, datetime_format)\n",
    "\n",
    "\n",
    "    # Update our datetime string with the converted\n",
    "    row[datetime_col_index] = datetime_object\n",
    "\n",
    "    # print(datetime_object)\n",
    "\n",
    "# Converting the CSV code to the right formats\n",
    "# timestamps ,floats, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row 1: Date: 2022-4-1, Time: 0:2\n",
      "Row 2: Date: 2022-4-1, Time: 0:3\n",
      "Row 3: Date: 2022-4-1, Time: 0:7\n",
      "Row 4: Date: 2022-4-1, Time: 0:9\n",
      "Row 5: Date: 2022-4-1, Time: 0:14\n"
     ]
    }
   ],
   "source": [
    "# More Cleaning \n",
    "for i in range(5):\n",
    "    dt = data[i][datetime_col_index]  # Assuming the datetime object is at datetime_col_index\n",
    "    year = dt.year\n",
    "    month = dt.month\n",
    "    day = dt.day\n",
    "    hour = dt.hour\n",
    "    minute = dt.minute\n",
    "    print(\"Row {}: Date: {}-{}-{}, Time: {}:{}\".format(i+1, year, month, day, hour, minute))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning Model\n",
    "\n",
    "In detailed and documented Python, walk the user through your code below similar to the Twitter assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning and Feature Extraction\n",
    "\n",
    "Add and describe code to perform Hyperparameter Tuning and Feature Extraction or PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visuals\n",
    "\n",
    "Below, generate the visuals that will explain the results you are getting and show what you hoped to learn from the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refection\n",
    "\n",
    "1. What issues did you encounter when aquiring and cleaning the data?\n",
    "2. What features did you use in your final model and why were others excluded?\n",
    "3. Which ML methods did you use and why? Which performed best before you started tuning? Did things change after tuning?\n",
    "4. What was your accuracy before and then after cross validation?\n",
    "5. What was the most challenging part of this project?"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "0333d40387376c9014aa4ff3a51f15c04ca086de5619d446c5c4e028c36297bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
